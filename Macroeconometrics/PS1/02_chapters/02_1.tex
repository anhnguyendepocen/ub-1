\subsection{Ergodic Stochastic Process}
A stochastic progress $x_t$ is given by the DGP
\begin{equation}
  \begin{split}
    x_t &= f(t) + \phi x_{t-1}+\varepsilon_t,\\
    \text{with }f(t) &= \mu \neq 0,\ \ \ \ \ |\phi|<1\ \text{and}\ \varepsilon_t\sim iid(0,\sigma^2_\varepsilon)
    \label{eq:xt}
  \end{split}
\end{equation}
$x_t$ is the realization of an ergodic stochastic process if it is stationary and for any point in time $t$ satisfies
\begin{equation}
  \displaystyle{\lim_{T\to\infty}}\left(T^{-1}\sum_{s=1}^TCov(x_t,x_{t+s})\right)=0
\end{equation}
That is, on average the memory of the process is bounded. Thus, covariances goes towards $0$ for two different point in time so that two parts of the same stochastic process can be independent from each other.
\\ \\
By iterative substitution we see that equation \ref{eq:xt} can be rewritten as
\begin{equation}
  \begin{split}
    x_t &= \mu + \phi x_{t-1} +\varepsilon_t \\
        &= \mu + \phi (\mu + \phi x_{t-2}+\varepsilon_{t-1}) +\varepsilon_t\\
        &= \mu (1+\phi) + \phi^2 x_{t-2}+ \phi\varepsilon_{t-1} +\varepsilon_t\\
        &= \mu (1+\phi) + \phi^2 (\mu + \phi x_{t-3}+\varepsilon_{t-2})+ \phi\varepsilon_{t-1}+\varepsilon_t\\
        &= \mu (1+\phi+\phi^2) + \phi^3(x_{t-3})+ \phi^2\varepsilon_{t-2} + \phi\varepsilon_{t-1} +\varepsilon_t\\
        &\vdots \\
        &= \phi^T x_{t-T} + \sum_{s=1}^T\left( \mu\phi^{s-1} + \phi^{s-1}\varepsilon_{t-s+1} \right)\\
        &\text{rewriting the sum of the geometric series:}\\
        &= \phi^T x_{t-T} + \mu\left(\frac{1-\phi^T}{1-\phi}\right) + \sum_{s=1}^T \phi^{s-1}\varepsilon_{t-s+1},\\
        &\ \text{where $T$ is the number of periods $s$ prior to $t$.}
        \label{eq:iterative}
  \end{split}
\end{equation}
If the process was a unit root the constant terms with $\mu$ would accumulate and produce a deterministic trend, but as $|\phi|<1$ then $\phi^T\xrightarrow[T\rightarrow\infty]{}0$ such that for a high number of periods $T$ equation \ref{eq:iterative} converges to
\begin{equation}
  \begin{split}
    x_t \xrightarrow[T\rightarrow\infty]{} \frac{\mu}{1-\phi} + \sum_{s=1}^T \phi^{s-1}\varepsilon_{t-s+1}
  \end{split}
\end{equation}
And as $\varepsilon_t$ is a stochastic term the expected realization of $_t$ will be
\begin{equation}
  \begin{split}
    E(x_t) = \frac{\mu}{1-\phi}
    \label{eq:mean}
  \end{split}
\end{equation}
As the expected mean is a constant then $\{x_t\}_{t=1}^T$ is an integrable $iid$ stochastic process and for $\mu<0$ the Law of large numbers implies that the mean converge in probability
\begin{equation}
  \bar{x}_T\xrightarrow{p}\frac{\mu}{1-\phi}
\end{equation}
Furthermore, we assume $T\rightarrow\infty$ then $x_t$ can be rewritten to a sequence of random variables $\{\tilde{x}_T\}_{T=1}^\infty$ that are drawn   from a population with a probability distribution with finite mean $\frac{\mu}{1-\phi}$ and finite variance $\sigma_\varepsilon^2$. The Central Limit Theorem then implies convergence to the normal distribution
\begin{equation}
  \sqrt{T}\left(\bar{x}-\frac{\mu}{1-\phi}\right) \xrightarrow{d}N(0,\sigma_\varepsilon^2)
\end{equation}
The derivations above shows that the memory of $x_t$ is bounded as the stationarity condition $|\phi|<1$ is fullfilled, thus the memory of the initial value $x_{t-T}$ and chock $\varepsilon_{t-T+1}$ decreases to zero the further away in time $t$ is from the initial period $t-T$.

Furthermore, the deterministic term given by the constant $\mu\neq0$ does not give rise to a linear trend, as $|\phi|<1$.

In conclusion, $x_t$ in equation \ref{eq:xt} indeed describes an ergodic stochastic process.

% This is even more clear when applying the difference operator with the order of integration $I(1)$ however would be an ergodic stochastic process as the deterministic parts would cancel each other out.
% \begin{equation}
%   \begin{split}
%     \Delta x_t  &= x_{t} - x_{t-1}\\
%                 &= [\mu + \phi x_{t-1} +\varepsilon_t] - [\mu + \phi x_{t-2} +\varepsilon_{t-1}]\\
%                 &= [\mu + \phi (\mu + \phi x_{t-2}+\varepsilon_{t-1}) +\varepsilon_t] - [\mu + \phi x_{t-2} +\varepsilon_{t-1}]\\
%                 &= \phi \mu + (\phi^2-\phi) x_{t-2} + (\phi-1) \varepsilon_{t-1} +\varepsilon_t\\
%                 &= \phi \mu + (\phi^2-\phi)(\mu + \phi x_{t-3}+ \varepsilon_{t-2}) + (\phi-1) \varepsilon_{t-1} +\varepsilon_t\\
%                 &= \phi^2 \mu + (\phi^3-\phi^2) x_{t-3}+ (\phi^2-\phi)\varepsilon_{t-2} + (\phi-1) \varepsilon_{t-1} +\varepsilon_t\\
%                 &\vdots\\
%                 &= \phi^{T-1}\mu + (\phi^T-\phi^{T-1}) x_{t-T} + \varepsilon_t +\sum_{s=2}^T (\phi^{s-1}-\phi^{s-2})\varepsilon_{t-s+1},\\
%         \label{eq:difference}
%   \end{split}
% \end{equation}
